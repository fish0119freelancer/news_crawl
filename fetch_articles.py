# fetch_articles.py (RSS ç‰ˆæœ¬)
import requests
from bs4 import BeautifulSoup
from datetime import datetime
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry
import warnings
from bs4 import XMLParsedAsHTMLWarning

# é—œé–‰ XML parser è­¦å‘Š
warnings.filterwarnings("ignore", category=XMLParsedAsHTMLWarning)

# å…±ç”¨ session + retry æ©Ÿåˆ¶
session = requests.Session()
retries = Retry(total=3, backoff_factor=1, status_forcelist=[500, 502, 503, 504])
session.mount("https://", HTTPAdapter(max_retries=retries))

# RSS feed URL (Nature Biomedical Engineering)
RSS_URL = "http://feeds.nature.com/natbiomedeng/rss/current"

# è§£æ RSS pubDate
def parse_rss_date(date_str: str) -> datetime:
    for fmt in (
        "%a, %d %b %Y %H:%M:%S %Z",
        "%a, %d %b %Y %H:%M:%S %z",
        "%Y-%m-%dT%H:%M:%SZ",
        "%Y-%m-%dT%H:%M:%S%z",
        "%Y-%m-%d"  # æœ‰äº› <dc:date> å¯èƒ½åªæœ‰æ—¥æœŸ
    ):
        try:
            return datetime.strptime(date_str, fmt)
        except ValueError:
            continue
    raise ValueError(f"ç„¡æ³•è§£ææ—¥æœŸæ ¼å¼ï¼š{date_str}")

# å¾ RSS æŠ“å–ã€Œç•¶å¤©ã€æ–‡ç« 
from datetime import timedelta

def fetch_today_from_rss(rss_url=RSS_URL):
    headers = {"User-Agent": "Mozilla/5.0 (compatible; NewsBot/1.0)"}
    resp = session.get(rss_url, headers=headers, timeout=20)
    resp.raise_for_status()

    soup = BeautifulSoup(resp.text, "xml")
    items = soup.find_all("item")
    
    # æ”¹ç”¨ç•¶åœ°æ™‚é–“ï¼ˆå°åŒ—ï¼‰ï¼Œä¸¦å…è¨±æ˜¨å¤©+ä»Šå¤©
    today = datetime.now().date()
    yesterday = today - timedelta(days=1)

    articles = []
    for item in items:
        link = item.find("link").get_text(strip=True) if item.find("link") else None
        title = item.find("title").get_text(strip=True) if item.find("title") else "(ç„¡æ¨™é¡Œ)"
        description = item.find("description").get_text(strip=True) if item.find("description") else ""
        pub_date_tag = item.find("pubDate") or item.find("dc:date")

        if not link or not pub_date_tag:
            continue

        try:
            pub_dt = parse_rss_date(pub_date_tag.get_text(strip=True))
            # å…è¨±æ˜¨å¤©æˆ–ä»Šå¤©
            if pub_dt.date() in (today, yesterday):
                articles.append({
                    "title": title,
                    "summary": description,
                    "publish_date": pub_dt.isoformat(),
                    "url": link
                })
        except Exception:
            continue

    return articles


if __name__ == "__main__":
    results = fetch_today_from_rss()
    if not results:
        print("ä»Šå¤©æ²’æœ‰æ‰¾åˆ°æ–°æ–‡ç« ")
    else:
        for art in results:
            print(f"ğŸ“Œ {art['title']} ({art['publish_date']})")
            print(f"æ‘˜è¦: {art['summary']}")
            print(f"é€£çµ: {art['url']}\n")
